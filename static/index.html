<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VoiceAI - Phase 4</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Silero VAD for Voice Activity Detection -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js"></script>
    <style>
        .message-user {
            background: #3b82f6;
            color: white;
            margin-left: auto;
        }
        .message-assistant {
            background: #10b981;
            color: white;
            margin-right: auto;
        }
        .message-transcript {
            background: #8b5cf6;
            color: white;
            margin-left: auto;
            border-left: 4px solid #6d28d9;
        }
        .message-status {
            background: #6b7280;
            color: white;
            margin: 0 auto;
            font-size: 0.875rem;
        }
        .message-error {
            background: #ef4444;
            color: white;
            margin: 0 auto;
        }
        .recording {
            animation: pulse 1.5s ease-in-out infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
        .vad-listening {
            animation: glow 2s ease-in-out infinite;
        }
        @keyframes glow {
            0%, 100% {
                box-shadow: 0 0 5px rgba(147, 51, 234, 0.5);
            }
            50% {
                box-shadow: 0 0 20px rgba(147, 51, 234, 0.8), 0 0 30px rgba(147, 51, 234, 0.6);
            }
        }
    </style>
</head>
<body class="bg-gray-100">
    <div class="container mx-auto px-4 py-8 max-w-4xl">
        <!-- Header -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-6">
            <h1 class="text-3xl font-bold text-gray-800 mb-2">üé≠ VoiceAI - Phase 4</h1>
            <p class="text-gray-600">Real-time Voice AI with STT, LLM & TTS</p>
        </div>

        <!-- Connection Status -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-6">
            <div class="flex items-center justify-between">
                <div class="flex-1">
                    <h2 class="text-xl font-semibold text-gray-800 mb-2">Connection Status</h2>
                    <p id="connection-status" class="text-gray-600">Disconnected</p>
                    <p id="session-id" class="text-sm text-gray-500 mt-1"></p>
                    <p id="websocket-url" class="text-xs text-gray-400 mt-1"></p>
                </div>
                <div>
                    <button id="connect-btn" onclick="connect()" class="bg-blue-500 hover:bg-blue-600 text-white px-6 py-2 rounded-lg font-medium">
                        Connect
                    </button>
                    <button id="disconnect-btn" onclick="disconnect()" class="bg-red-500 hover:bg-red-600 text-white px-6 py-2 rounded-lg font-medium ml-2 hidden">
                        Disconnect
                    </button>
                </div>
            </div>
        </div>

        <!-- Audio Controls -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-6">
            <h2 class="text-xl font-semibold text-gray-800 mb-4">üé§ Voice Input</h2>

            <!-- Voice Chat Mode (VAD) -->
            <div class="mb-4 p-4 bg-gradient-to-r from-purple-50 to-blue-50 rounded-lg border-2 border-purple-200">
                <div class="flex items-center justify-between mb-2">
                    <div>
                        <h3 class="font-semibold text-gray-800">üéôÔ∏è Voice Chat Mode (Auto VAD)</h3>
                        <p class="text-sm text-gray-600">Hands-free conversation - auto-detects when you speak!</p>
                    </div>
                    <button
                        id="voice-chat-btn"
                        onclick="toggleVoiceChat()"
                        class="bg-purple-500 hover:bg-purple-600 text-white px-6 py-3 rounded-lg font-medium disabled:opacity-50 disabled:cursor-not-allowed transition-all"
                        disabled
                    >
                        üöÄ Start Voice Chat
                    </button>
                </div>
                <div id="vad-status" class="text-sm font-medium text-gray-700 mt-2 hidden">
                    <span id="vad-status-text">Initializing VAD...</span>
                </div>
            </div>

            <!-- Manual Recording (Old way) -->
            <div class="p-4 bg-gray-50 rounded-lg">
                <h3 class="font-semibold text-gray-700 mb-2">Manual Recording</h3>
                <div class="flex gap-2 items-center">
                    <button
                        id="record-btn"
                        onclick="toggleRecording()"
                        class="bg-blue-500 hover:bg-blue-600 text-white px-6 py-3 rounded-lg font-medium disabled:opacity-50 disabled:cursor-not-allowed"
                        disabled
                    >
                        üé§ Start Recording
                    </button>
                    <div id="recording-indicator" class="hidden">
                        <span class="recording text-red-600 font-semibold">‚óè Recording...</span>
                    </div>
                    <div id="audio-status" class="text-sm text-gray-600 ml-4"></div>
                </div>
            </div>
        </div>

        <!-- Chat Area -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-6">
            <h2 class="text-xl font-semibold text-gray-800 mb-4">üí¨ Chat</h2>

            <!-- Messages -->
            <div id="messages" class="h-96 overflow-y-auto mb-4 p-4 bg-gray-50 rounded-lg space-y-2">
                <div class="text-gray-500 text-center text-sm">
                    No messages yet. Connect and start chatting!
                </div>
            </div>

            <!-- Input -->
            <div class="flex gap-2">
                <input
                    type="text"
                    id="message-input"
                    placeholder="Type your message (Vietnamese or English)..."
                    class="flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
                    onkeypress="handleKeyPress(event)"
                    disabled
                />
                <button
                    id="send-btn"
                    onclick="sendMessage()"
                    class="bg-green-500 hover:bg-green-600 text-white px-6 py-2 rounded-lg font-medium disabled:opacity-50 disabled:cursor-not-allowed"
                    disabled
                >
                    Send
                </button>
                <button
                    onclick="clearMessages()"
                    class="bg-gray-500 hover:bg-gray-600 text-white px-6 py-2 rounded-lg font-medium"
                >
                    Clear
                </button>
            </div>
        </div>
    </div>

    <script>
        let ws = null;
        let sessionId = null;
        let currentAssistantMessage = null;

        // Audio recording
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let audioStream = null;

        // Voice Chat Mode (VAD)
        let vad = null;
        let isVoiceChatMode = false;
        let vadAudioChunks = [];
        let isSpeaking = false;
        let isAIResponding = false;
        let currentAudio = null; // Track currently playing audio

        function connect() {
            // Auto-detect WebSocket URL based on current location
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const host = window.location.host;  // includes hostname and port
            const wsUrl = `${protocol}//${host}/ws`;
            
            console.log('Connecting to:', wsUrl);
            document.getElementById('websocket-url').textContent = `WebSocket: ${wsUrl}`;

            try {
                ws = new WebSocket(wsUrl);

                ws.onopen = () => {
                    updateConnectionStatus('Connected', true);
                    document.getElementById('message-input').disabled = false;
                    document.getElementById('send-btn').disabled = false;
                    document.getElementById('record-btn').disabled = false;
                    document.getElementById('voice-chat-btn').disabled = false;
                };

                ws.onmessage = (event) => {
                    handleMessage(JSON.parse(event.data));
                };

                ws.onclose = () => {
                    updateConnectionStatus('Disconnected', false);
                    document.getElementById('message-input').disabled = true;
                    document.getElementById('send-btn').disabled = true;
                    document.getElementById('record-btn').disabled = true;
                    document.getElementById('voice-chat-btn').disabled = true;
                    ws = null;
                    sessionId = null;
                };

                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    addMessage('error', 'Connection error occurred');
                };

            } catch (error) {
                console.error('Failed to connect:', error);
                addMessage('error', 'Failed to connect to server');
            }
        }

        function disconnect() {
            if (isRecording) {
                stopRecording();
            }
            if (isVoiceChatMode) {
                stopVoiceChat();
            }
            if (ws) {
                ws.close();
            }
        }

        async function toggleVoiceChat() {
            if (isVoiceChatMode) {
                await stopVoiceChat();
            } else {
                await startVoiceChat();
            }
        }

        async function startVoiceChat() {
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                alert('Please connect to the server first');
                return;
            }

            try {
                updateVADStatus('Initializing VAD...', 'text-blue-600');
                document.getElementById('vad-status').classList.remove('hidden');

                // Initialize VAD
                vad = await window.vad.MicVAD.new({
                    onSpeechStart: () => {
                        console.log('Speech started');

                        // If AI is currently speaking, INTERRUPT it!
                        if (isAIResponding || isPlaying) {
                            console.log('üõë User interrupted AI - stopping playback');
                            interruptAI();
                            addMessage('status', 'üõë Interrupted - listening to you...');
                        }

                        isSpeaking = true;
                        vadAudioChunks = [];
                        updateVADStatus('üé§ Listening... (Speak now)', 'text-green-600');

                        if (!isAIResponding) {
                            addMessage('status', 'üé§ Listening...');
                        }
                    },
                    onSpeechEnd: async (audio) => {
                        console.log('Speech ended, processing...');
                        isSpeaking = false;
                        updateVADStatus('‚è≥ Processing speech...', 'text-yellow-600');

                        // Convert Float32Array to audio blob
                        const audioBlob = await convertAudioToBlob(audio);

                        // Send directly as complete audio (no streaming)
                        await sendCompleteAudioToServer(audioBlob);
                    },
                    onVADMisfire: () => {
                        console.log('VAD misfire - false positive');
                        isSpeaking = false;
                        if (isVoiceChatMode && !isAIResponding) {
                            updateVADStatus('üëÇ Waiting for speech...', 'text-gray-600');
                        }
                    },
                    positiveSpeechThreshold: 0.7,  // Lower = more sensitive (detect faster)
                    negativeSpeechThreshold: 0.4,   // Lower = detect silence faster
                    redemptionFrames: 5,            // Fewer frames = faster interrupt detection
                    preSpeechPadFrames: 1,
                    minSpeechFrames: 3,             // Fewer frames = faster speech detection
                });

                await vad.start();
                isVoiceChatMode = true;
                isAIResponding = false;

                // Update UI
                document.getElementById('voice-chat-btn').textContent = '‚èπ Stop Voice Chat';
                document.getElementById('voice-chat-btn').classList.remove('bg-purple-500', 'hover:bg-purple-600');
                document.getElementById('voice-chat-btn').classList.add('bg-red-500', 'hover:bg-red-600');
                document.getElementById('record-btn').disabled = true;
                updateVADStatus('üëÇ Waiting for speech...', 'text-gray-600');

                addMessage('status', 'üöÄ Voice Chat Mode activated! Speak naturally - I\'ll auto-detect your voice.');

            } catch (error) {
                console.error('Failed to start Voice Chat:', error);
                addMessage('error', `Failed to start Voice Chat: ${error.message}`);
                updateVADStatus('Error initializing VAD', 'text-red-600');
            }
        }

        function interruptAI() {
            console.log('Interrupting AI...');

            // Stop current audio immediately
            if (currentAudio) {
                currentAudio.pause();
                currentAudio.currentTime = 0;
                currentAudio = null;
            }

            // Clear all pending audio
            audioQueue.forEach(url => URL.revokeObjectURL(url));
            audioQueue = [];
            isPlaying = false;
            isAIResponding = false;

            console.log('AI interrupted - ready for new input');
        }

        async function stopVoiceChat() {
            if (vad) {
                try {
                    // Pause first to stop listening immediately
                    if (typeof vad.pause === 'function') {
                        vad.pause();
                        console.log('VAD paused');
                    }
                    // Then destroy if available
                    if (typeof vad.destroy === 'function') {
                        await vad.destroy();
                        console.log('VAD destroyed');
                    }
                } catch (error) {
                    console.error('Error stopping VAD:', error);
                }
                vad = null;
            }

            isVoiceChatMode = false;
            isSpeaking = false;
            isAIResponding = false;

            // Clear audio queue to prevent any remaining audio from playing
            interruptAI();

            // Update UI
            document.getElementById('voice-chat-btn').textContent = 'üöÄ Start Voice Chat';
            document.getElementById('voice-chat-btn').classList.remove('bg-red-500', 'hover:bg-red-600');
            document.getElementById('voice-chat-btn').classList.add('bg-purple-500', 'hover:bg-purple-600');
            document.getElementById('record-btn').disabled = false;
            document.getElementById('vad-status').classList.add('hidden');

            addMessage('status', '‚èπ Voice Chat Mode deactivated');
        }

        function updateVADStatus(text, colorClass) {
            const statusEl = document.getElementById('vad-status-text');
            const statusContainer = document.getElementById('vad-status');

            statusEl.textContent = text;
            statusEl.className = colorClass;

            // Add glow effect when listening or speaking
            if (text.includes('Listening') || text.includes('Speak now')) {
                statusContainer.classList.add('vad-listening');
            } else {
                statusContainer.classList.remove('vad-listening');
            }
        }

        async function convertAudioToBlob(float32Array) {
            // Convert Float32Array to WAV format
            const sampleRate = 16000;
            const numChannels = 1;
            const bitsPerSample = 16;

            const dataLength = float32Array.length * (bitsPerSample / 8);
            const buffer = new ArrayBuffer(44 + dataLength);
            const view = new DataView(buffer);

            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };

            writeString(0, 'RIFF');
            view.setUint32(4, 36 + dataLength, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * numChannels * (bitsPerSample / 8), true);
            view.setUint16(32, numChannels * (bitsPerSample / 8), true);
            view.setUint16(34, bitsPerSample, true);
            writeString(36, 'data');
            view.setUint32(40, dataLength, true);

            // Convert Float32Array to Int16Array
            let offset = 44;
            for (let i = 0; i < float32Array.length; i++) {
                const sample = Math.max(-1, Math.min(1, float32Array[i]));
                const int16Sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                view.setInt16(offset, int16Sample, true);
                offset += 2;
            }

            return new Blob([buffer], { type: 'audio/wav' });
        }

        async function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                await startRecording();
            }
        }

        async function startRecording() {
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                alert('Please connect to the server first');
                return;
            }

            try {
                // Request microphone access
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true  // Better audio quality
                    }
                });

                // Create media recorder
                mediaRecorder = new MediaRecorder(audioStream, {
                    mimeType: 'audio/webm;codecs=opus'
                });

                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    // Combine all chunks
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await sendAudioToServer(audioBlob);
                    
                    // Clean up
                    if (audioStream) {
                        audioStream.getTracks().forEach(track => track.stop());
                        audioStream = null;
                    }
                };

                // Send start recording message
                const startMsg = {
                    type: 'start_recording',
                    data: {},
                    session_id: sessionId
                };
                ws.send(JSON.stringify(startMsg));

                // Start recording
                mediaRecorder.start();
                isRecording = true;

                // Update UI
                document.getElementById('record-btn').textContent = '‚èπ Stop Recording';
                document.getElementById('record-btn').classList.remove('bg-blue-500', 'hover:bg-blue-600');
                document.getElementById('record-btn').classList.add('bg-red-500', 'hover:bg-red-600');
                document.getElementById('recording-indicator').classList.remove('hidden');
                document.getElementById('audio-status').textContent = 'Recording...';

                addMessage('status', 'üé§ Recording started');

            } catch (error) {
                console.error('Failed to start recording:', error);
                addMessage('error', `Failed to access microphone: ${error.message}`);
            }
        }

        function stopRecording() {
            if (!isRecording || !mediaRecorder) return;

            mediaRecorder.stop();
            isRecording = false;

            // Update UI
            document.getElementById('record-btn').textContent = 'üé§ Start Recording';
            document.getElementById('record-btn').classList.remove('bg-red-500', 'hover:bg-red-600');
            document.getElementById('record-btn').classList.add('bg-blue-500', 'hover:bg-blue-600');
            document.getElementById('recording-indicator').classList.add('hidden');
            document.getElementById('audio-status').textContent = 'Processing...';

            addMessage('status', '‚èπ Recording stopped, processing...');
        }

        async function sendAudioToServer(audioBlob) {
            try {
                // Convert blob to array buffer
                const arrayBuffer = await audioBlob.arrayBuffer();
                const uint8Array = new Uint8Array(arrayBuffer);

                // Convert to base64
                let binary = '';
                const len = uint8Array.byteLength;
                for (let i = 0; i < len; i++) {
                    binary += String.fromCharCode(uint8Array[i]);
                }
                const base64Audio = btoa(binary);

                // Send audio chunk message
                const audioMsg = {
                    type: 'audio_chunk',
                    data: {
                        audio: base64Audio
                    },
                    session_id: sessionId
                };
                ws.send(JSON.stringify(audioMsg));

                // Send stop recording message
                const stopMsg = {
                    type: 'stop_recording',
                    data: {},
                    session_id: sessionId
                };
                ws.send(JSON.stringify(stopMsg));

                document.getElementById('audio-status').textContent = `Sent ${audioBlob.size} bytes`;

            } catch (error) {
                console.error('Failed to send audio:', error);
                addMessage('error', `Failed to send audio: ${error.message}`);
                document.getElementById('audio-status').textContent = 'Error sending audio';
            }
        }

        async function sendCompleteAudioToServer(audioBlob) {
            try {
                // Convert blob to array buffer
                const arrayBuffer = await audioBlob.arrayBuffer();
                const uint8Array = new Uint8Array(arrayBuffer);

                // Convert to base64
                let binary = '';
                const len = uint8Array.byteLength;
                for (let i = 0; i < len; i++) {
                    binary += String.fromCharCode(uint8Array[i]);
                }
                const base64Audio = btoa(binary);

                console.log(`Sending complete audio: ${audioBlob.size} bytes`);

                // Send as complete audio directly (VAD mode)
                const audioMsg = {
                    type: 'vad_audio',
                    data: {
                        audio: base64Audio,
                        format: 'wav'
                    },
                    session_id: sessionId
                };
                ws.send(JSON.stringify(audioMsg));

            } catch (error) {
                console.error('Failed to send VAD audio:', error);
                addMessage('error', `Failed to send audio: ${error.message}`);
                if (isVoiceChatMode) {
                    updateVADStatus('Error sending audio', 'text-red-600');
                }
            }
        }

        function sendMessage() {
            const input = document.getElementById('message-input');
            const text = input.value.trim();

            if (!text || !ws) return;

            const message = {
                type: 'text_input',
                data: {
                    text: text
                },
                session_id: sessionId
            };

            ws.send(JSON.stringify(message));
            addMessage('user', text);
            input.value = '';

            // Prepare for streaming assistant response
            currentAssistantMessage = null;
        }

        function handleMessage(message) {
            console.log('Received:', message);

            if (message.session_id && !sessionId) {
                sessionId = message.session_id;
                document.getElementById('session-id').textContent = `Session: ${sessionId.substring(0, 8)}...`;
            }

            switch (message.type) {
                case 'status':
                    addMessage('status', message.data.status);
                    break;

                case 'text_response':
                    // Handle streaming text response
                    const text = message.data.text;
                    if (!currentAssistantMessage) {
                        currentAssistantMessage = addMessage('assistant', text);
                    } else {
                        currentAssistantMessage.textContent += text;
                        scrollToBottom();
                    }
                    break;

                case 'transcript':
                    // Show transcribed text
                    addMessage('transcript', `üé§ "${message.data.transcript}"`);
                    if (isVoiceChatMode) {
                        updateVADStatus('üí≠ AI is thinking...', 'text-blue-600');
                        isAIResponding = true;
                        // Keep VAD running to detect interrupts!
                        console.log('AI is responding - VAD still listening for interrupts');
                    }
                    break;

                case 'audio_response':
                    // Play audio response
                    playAudioResponse(message.data.audio);
                    break;

                case 'error':
                    addMessage('error', message.data.error);
                    document.getElementById('audio-status').textContent = 'Error';
                    break;

                case 'pong':
                    console.log('Pong received');
                    break;

                default:
                    console.log('Unknown message type:', message.type);
            }
        }

        let audioQueue = [];
        let isPlaying = false;

        function playAudioResponse(audioBase64) {
            try {
                // Convert base64 to blob
                const audioData = atob(audioBase64);
                const arrayBuffer = new ArrayBuffer(audioData.length);
                const uint8Array = new Uint8Array(arrayBuffer);
                
                for (let i = 0; i < audioData.length; i++) {
                    uint8Array[i] = audioData.charCodeAt(i);
                }
                
                const blob = new Blob([uint8Array], { type: 'audio/mpeg' });
                const audioUrl = URL.createObjectURL(blob);
                
                console.log(`Received audio: ${(audioData.length / 1024).toFixed(2)} KB`);
                
                // Add to queue and play
                audioQueue.push(audioUrl);
                processAudioQueue();
                
            } catch (error) {
                console.error('Error processing audio:', error);
                addMessage('error', 'Failed to process audio response');
            }
        }

        function processAudioQueue() {
            if (isPlaying || audioQueue.length === 0) return;

            isPlaying = true;
            const audioUrl = audioQueue.shift();
            const audio = new Audio(audioUrl);
            currentAudio = audio; // Track current audio for interrupt

            console.log(`Playing audio (${audioQueue.length} remaining in queue)`);

            audio.onended = () => {
                URL.revokeObjectURL(audioUrl);
                currentAudio = null;
                isPlaying = false;
                console.log('Audio finished');

                // If queue is empty and Voice Chat Mode is active, restart listening
                if (audioQueue.length === 0 && isVoiceChatMode) {
                    isAIResponding = false;
                    updateVADStatus('üëÇ Waiting for speech...', 'text-gray-600');
                    addMessage('status', 'üëÇ Ready - speak when you\'re ready!');
                } else {
                    // Play next immediately
                    processAudioQueue();
                }
            };

            audio.onerror = (e) => {
                console.error('Audio playback error:', e);
                URL.revokeObjectURL(audioUrl);
                currentAudio = null;
                isPlaying = false;
                processAudioQueue();
            };

            audio.play().catch(error => {
                console.error('Error playing audio:', error);
                URL.revokeObjectURL(audioUrl);
                currentAudio = null;
                isPlaying = false;
                processAudioQueue();
            });
        }

        function addMessage(type, content) {
            const messagesDiv = document.getElementById('messages');

            // Clear placeholder
            if (messagesDiv.children.length === 1 &&
                messagesDiv.children[0].textContent.includes('No messages yet')) {
                messagesDiv.innerHTML = '';
            }

            const messageDiv = document.createElement('div');
            messageDiv.className = `message-${type} px-4 py-2 rounded-lg max-w-md break-words`;
            messageDiv.textContent = content;

            messagesDiv.appendChild(messageDiv);
            scrollToBottom();

            return messageDiv;
        }

        function clearMessages() {
            const messagesDiv = document.getElementById('messages');
            messagesDiv.innerHTML = '<div class="text-gray-500 text-center text-sm">Messages cleared</div>';
            currentAssistantMessage = null;
        }

        function scrollToBottom() {
            const messagesDiv = document.getElementById('messages');
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }

        function updateConnectionStatus(status, connected) {
            const statusElement = document.getElementById('connection-status');
            statusElement.textContent = status;
            statusElement.className = connected ? 'text-green-600 font-semibold' : 'text-red-600';

            document.getElementById('connect-btn').classList.toggle('hidden', connected);
            document.getElementById('disconnect-btn').classList.toggle('hidden', !connected);
        }

        function handleKeyPress(event) {
            if (event.key === 'Enter') {
                sendMessage();
            }
        }

        // Ping to keep connection alive
        setInterval(() => {
            if (ws && ws.readyState === WebSocket.OPEN) {
                const ping = {
                    type: 'ping',
                    data: {},
                    session_id: sessionId
                };
                ws.send(JSON.stringify(ping));
            }
        }, 30000); // Every 30 seconds
    </script>
</body>
</html>
